{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d47693e4",
   "metadata": {},
   "source": [
    "\n",
    "# Retail Store Sales — EDA & Cleaning Notebook\n",
    "\n",
    "This notebook consolidates your three Python scripts into a single, streamlined workflow for:\n",
    "1) **Extraction / Loading & Quick Audit**\n",
    "2) **Exploratory Data Analysis (EDA)**\n",
    "3) **Cleaning + Intelligent Filling + Exports**\n",
    "\n",
    "**Key improvements vs. the original scripts:**\n",
    "- Single CSV read (no repeated I/O).\n",
    "- Robust type coercions and validation, without overwriting the original raw file.\n",
    "- All plots rendered with **matplotlib only** (no seaborn), which is simpler and self-contained.\n",
    "- Reusable helper functions to avoid duplication.\n",
    "- Clear save locations for artifacts (JSON summaries, cleaned CSVs, and charts).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af76e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\etl_online_retail_project\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports & settings\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas display prefs (safe for notebooks)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Paths\n",
    "PROJECT_DIR = r\"C:\\Users\\matth\\etl_online_retail_project\"\n",
    "print(PROJECT_DIR)\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "RAW_DATA_PATH = os.path.join(DATA_DIR, 'retail_store_sales.csv')\n",
    "\n",
    "# Output directories\n",
    "ARTIFACTS_DIR = os.path.join(DATA_DIR, 'artifacts')\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "# Common column groups\n",
    "NUMERIC_COLS = ['Price Per Unit', 'Quantity', 'Total Spent']\n",
    "CATEGORICAL_COLS = ['Category', 'Payment Method', 'Location', 'Discount Applied']\n",
    "DATE_COL = 'Transaction Date'\n",
    "KEY_COL = 'Transaction ID'  # used for duplicate checks, if present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c89165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "\n",
    "def safe_read_csv(path):\n",
    "    \"\"\"Read CSV with UTF-8 fallback to latin-1, without overwriting the raw file.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding='latin1')\n",
    "\n",
    "def coerce_types(df):\n",
    "    \"\"\"Coerce expected dtypes for EDA/cleaning.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Date\n",
    "    if DATE_COL in df.columns:\n",
    "        df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors='coerce')\n",
    "    # Numerics\n",
    "    for col in NUMERIC_COLS:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    # Discount Applied to boolean (with NaN preserved)\n",
    "    if 'Discount Applied' in df.columns:\n",
    "        # Map strings to booleans where clear, preserve NaN\n",
    "        ser = df['Discount Applied'].astype(str).str.strip().str.lower()\n",
    "        mapped = ser.map({'true': True, 'false': False})\n",
    "        df['Discount Applied'] = mapped.where(~ser.isin(['nan', 'none', '']), np.nan)\n",
    "    return df\n",
    "\n",
    "def quick_audit(df):\n",
    "    \"\"\"Return a concise dict of dataset stats.\"\"\"\n",
    "    mem_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_pct = (missing_values / len(df)) * 100\n",
    "    dtypes_count = {str(dt): int((df.dtypes == dt).sum()) for dt in df.dtypes.unique()}\n",
    "    return {\n",
    "        'shape': df.shape,\n",
    "        'memory_mb': round(mem_mb, 1),\n",
    "        'dtype_counts': dtypes_count,\n",
    "        'total_missing_cells': int(missing_values.sum()),\n",
    "        'missing_pct': float((missing_values.sum() / (len(df) * len(df.columns))) * 100),\n",
    "        'missing_df': pd.DataFrame({\n",
    "            'Column': missing_values.index,\n",
    "            'Missing_Count': missing_values.values,\n",
    "            'Missing_Percentage': missing_pct.values\n",
    "        }).sort_values('Missing_Count', ascending=False)\n",
    "    }\n",
    "\n",
    "def validate_financials(df, tolerance=0.01):\n",
    "    \"\"\"Check Price*Quantity vs Total Spent discrepancies.\"\"\"\n",
    "    if not all(col in df.columns for col in NUMERIC_COLS):\n",
    "        return 0\n",
    "    complete = df.dropna(subset=NUMERIC_COLS)\n",
    "    if complete.empty:\n",
    "        return 0\n",
    "    calc_total = complete['Price Per Unit'] * complete['Quantity']\n",
    "    discrep = (calc_total - complete['Total Spent']).abs() > tolerance\n",
    "    return int(discrep.sum())\n",
    "\n",
    "def detect_date_anomalies(df):\n",
    "    \"\"\"Future/past date checks based on current year and >= 2020 lower bound.\"\"\"\n",
    "    if DATE_COL not in df.columns:\n",
    "        return 0, 0\n",
    "    current_year = datetime.now().year\n",
    "    future = df[df[DATE_COL].dt.year > current_year]\n",
    "    past = df[df[DATE_COL].dt.year < 2020]\n",
    "    return len(future), len(past)\n",
    "\n",
    "def save_json(obj, filename):\n",
    "    path = os.path.join(ARTIFACTS_DIR, filename)\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(obj, f, indent=2, default=str)\n",
    "    return path\n",
    "\n",
    "def plot_missing(missing_df, filename='missing_values.png'):\n",
    "    miss = missing_df[missing_df['Missing_Count'] > 0]\n",
    "    if miss.empty:\n",
    "        return None\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(miss['Column'], miss['Missing_Percentage'])\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.xlabel('Column')\n",
    "    plt.ylabel('Missing Percentage')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    out = os.path.join(ARTIFACTS_DIR, filename)\n",
    "    plt.savefig(out, dpi=300, bbox_inches='tight')\n",
    "   # plt.show()   \n",
    "    return out\n",
    "\n",
    "def plot_outliers(df, filename='outlier_detection.png'):\n",
    "    cols = [c for c in NUMERIC_COLS if c in df.columns]\n",
    "    if not cols:\n",
    "        return None\n",
    "    n = len(cols)\n",
    "    plt.figure(figsize=(5*n, 5))\n",
    "    for i, col in enumerate(cols, 1):\n",
    "        plt.subplot(1, n, i)\n",
    "        df.boxplot(column=col)\n",
    "        plt.title(f'{col} Distribution')\n",
    "    plt.tight_layout()\n",
    "    out = os.path.join(ARTIFACTS_DIR, filename)\n",
    "    plt.savefig(out, dpi=300, bbox_inches='tight')\n",
    "  #  plt.show()   \n",
    "    return out\n",
    "\n",
    "def plot_categorical_distributions(df, filename='categorical_distributions.png'):\n",
    "    cols = [c for c in CATEGORICAL_COLS if c in df.columns]\n",
    "    if not cols:\n",
    "        return None\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, col in enumerate(cols[:4], 1):\n",
    "        plt.subplot(2, 2, i)\n",
    "        vc = df[col].value_counts().head(10)\n",
    "        plt.bar(vc.index.astype(str), vc.values)\n",
    "        plt.title(f'{col} Distribution')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    out = os.path.join(ARTIFACTS_DIR, filename)\n",
    "    plt.savefig(out, dpi=300, bbox_inches='tight')\n",
    "   # plt.show()   \n",
    "    return out\n",
    "def to_cents(x):\n",
    "    \"\"\"Convert a numeric dollar value to integer cents, handling NaN safely.\"\"\"\n",
    "    if pd.isna(x): \n",
    "        return 0\n",
    "    return int(round(float(x) * 100.0))\n",
    "\n",
    "def norm_channel(loc_value: str) -> str:\n",
    "    \"\"\"Normalize location/channel into 'Online' or 'In-Store'.\"\"\"\n",
    "    if pd.isna(loc_value):\n",
    "        return \"Online\"\n",
    "    s = str(loc_value).strip().lower()\n",
    "    return \"In-Store\" if s in (\"in-store\",\"instore\",\"in store\",\"in-store\") else \"Online\"\n",
    "\n",
    "def boolish_to_int(x):\n",
    "    \"\"\"Map True/False/yes/no/1/0 strings to 1/0 for SQLite.\"\"\"\n",
    "    if isinstance(x, (bool, np.bool_)):\n",
    "        return int(x)\n",
    "    if pd.isna(x):\n",
    "        return 0\n",
    "    s = str(x).strip().lower()\n",
    "    return 1 if s in (\"true\",\"1\",\"yes\",\"y\",\"t\") else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1860af",
   "metadata": {},
   "source": [
    "## 1) Ingest Raw Retail Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d7f751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: 12,575 rows × 11 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Item</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "      <th>Discount Applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_6867343</td>\n",
       "      <td>CUST_09</td>\n",
       "      <td>Patisserie</td>\n",
       "      <td>Item_10_PAT</td>\n",
       "      <td>18.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_3731986</td>\n",
       "      <td>CUST_22</td>\n",
       "      <td>Milk Products</td>\n",
       "      <td>Item_17_MILK</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_9303719</td>\n",
       "      <td>CUST_02</td>\n",
       "      <td>Butchers</td>\n",
       "      <td>Item_12_BUT</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_9458126</td>\n",
       "      <td>CUST_06</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Item_16_BEV</td>\n",
       "      <td>27.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>247.5</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_4575373</td>\n",
       "      <td>CUST_05</td>\n",
       "      <td>Food</td>\n",
       "      <td>Item_6_FOOD</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID Customer ID       Category          Item  Price Per Unit  \\\n",
       "0    TXN_6867343     CUST_09     Patisserie   Item_10_PAT            18.5   \n",
       "1    TXN_3731986     CUST_22  Milk Products  Item_17_MILK            29.0   \n",
       "2    TXN_9303719     CUST_02       Butchers   Item_12_BUT            21.5   \n",
       "3    TXN_9458126     CUST_06      Beverages   Item_16_BEV            27.5   \n",
       "4    TXN_4575373     CUST_05           Food   Item_6_FOOD            12.5   \n",
       "\n",
       "   Quantity  Total Spent  Payment Method Location Transaction Date  \\\n",
       "0      10.0        185.0  Digital Wallet   Online       2024-04-08   \n",
       "1       9.0        261.0  Digital Wallet   Online       2023-07-23   \n",
       "2       2.0         43.0     Credit Card   Online       2022-10-05   \n",
       "3       9.0        247.5     Credit Card   Online       2022-05-07   \n",
       "4       7.0         87.5  Digital Wallet   Online       2022-10-02   \n",
       "\n",
       "  Discount Applied  \n",
       "0             True  \n",
       "1             True  \n",
       "2            False  \n",
       "3              NaN  \n",
       "4            False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_raw = safe_read_csv(RAW_DATA_PATH)\n",
    "print(f\"Data shape: {df_raw.shape[0]:,} rows × {df_raw.shape[1]} columns\")\n",
    "\n",
    "# Show columns at a glance\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614b6d03",
   "metadata": {},
   "source": [
    "## 2) Data Quality & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12965bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5.6 MB\n",
      "Dtype counts: {'object': 7, 'float64': 3, 'datetime64[ns]': 1}\n",
      "Total missing cells: 7,229 (5.2%)\n",
      "              Column  Missing_Count  Missing_Percentage\n",
      "10  Discount Applied           4199           33.391650\n",
      "3               Item           1213            9.646123\n",
      "4     Price Per Unit            609            4.842942\n",
      "5           Quantity            604            4.803181\n",
      "6        Total Spent            604            4.803181\n",
      "0     Transaction ID              0            0.000000\n",
      "1        Customer ID              0            0.000000\n",
      "2           Category              0            0.000000\n",
      "7     Payment Method              0            0.000000\n",
      "8           Location              0            0.000000\n",
      "9   Transaction Date              0            0.000000\n",
      "{'future_dates': 0, 'pre_2020_dates': 0, 'financial_discrepancies': 0, 'exact_duplicates': 0, 'key_duplicates': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = coerce_types(df_raw)\n",
    "audit = quick_audit(df)\n",
    "\n",
    "print(f\"Memory usage: {audit['memory_mb']} MB\\nDtype counts: {audit['dtype_counts']}\\n\"\n",
    "      f\"Total missing cells: {audit['total_missing_cells']:,} \"\n",
    "      f\"({audit['missing_pct']:.1f}%)\") \n",
    "\n",
    "print(audit['missing_df'].head(20))\n",
    "\n",
    "future_cnt, past_cnt = detect_date_anomalies(df)\n",
    "discrep_cnt = validate_financials(df)\n",
    "\n",
    "exact_duplicates = int(df.duplicated().sum())\n",
    "key_duplicates = int(df.duplicated(subset=[KEY_COL]).sum()) if KEY_COL in df.columns else 0\n",
    "\n",
    "quality_flags = {\n",
    "    'future_dates': future_cnt,\n",
    "    'pre_2020_dates': past_cnt,\n",
    "    'financial_discrepancies': discrep_cnt,\n",
    "    'exact_duplicates': exact_duplicates,\n",
    "    'key_duplicates': key_duplicates\n",
    "}\n",
    "\n",
    "print(quality_flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0c2ff",
   "metadata": {},
   "source": [
    "## 3) Automated Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fc96c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repaired 4,019 rows with discount mismatch by inferring discount from Price×Quantity vs Total.\n",
      "\n",
      "=== CLEANING SUMMARY ===\n",
      "Original rows:                    12,575\n",
      "After exact-dup drop:             12,575 (removed 0)\n",
      "Analysis-ready rows (post-repair): 11,362\n",
      "Incomplete/QA rows (post-repair):  1,213\n",
      "Intelligent fill: {'totals_from_price_qty': 0, 'price_from_total_qty': 609, 'qty_from_total_price': 0}\n",
      "\n",
      "[Pre-repair] Rows flagged by each rule:\n",
      "discount_mismatch          4019\n",
      "future_date                   0\n",
      "pre2020_date                  0\n",
      "negative_Price Per Unit       0\n",
      "negative_Quantity             0\n",
      "negative_Total Spent          0\n",
      "discrepancy_total             0\n",
      "dtype: int64\n",
      "\n",
      "[Post-repair] Rows flagged by each rule:\n",
      "future_date                0\n",
      "pre2020_date               0\n",
      "negative_Price Per Unit    0\n",
      "negative_Quantity          0\n",
      "negative_Total Spent       0\n",
      "discrepancy_total          0\n",
      "discount_mismatch          0\n",
      "txn_duplicate              0\n",
      "dtype: int64\n",
      "\n",
      "=== Improvements ===\n",
      "Discount mismatch rows repaired: 4,019 of 4,019 (100.0%) — via inferred discount from Price×Quantity vs Total.\n",
      "Rows directly updated in repair step: 4,019 (fields normalized: 'Discount Applied', 'Discount_Amount', 'Discount_Percentage').\n",
      "\n",
      "Flag columns removed from analysis-ready/full-cleaned outputs: ['flag_future_date', 'flag_pre2020_date', 'flag_negative_Price Per Unit', 'flag_negative_Quantity', 'flag_negative_Total Spent', 'flag_discrepancy_total', 'flag_discount_mismatch', 'flag_txn_duplicate']\n"
     ]
    }
   ],
   "source": [
    "# === Cleaning aligned to the outlined practices (uses provided helpers) ===\n",
    "TOL = 0.01  # 1-cent tolerance for financial checks\n",
    "\n",
    "# Start from coerced types to ensure safe operations\n",
    "df_clean = coerce_types(df)\n",
    "initial_records = len(df_clean)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) DATES\n",
    "# ---------------------------\n",
    "# Quarantine invalid/null dates; keep for QA review\n",
    "quarantine_dates = pd.DataFrame(columns=df_clean.columns)\n",
    "if DATE_COL in df_clean.columns:\n",
    "    invalid_date_mask = df_clean[DATE_COL].isna()\n",
    "    if invalid_date_mask.any():\n",
    "        quarantine_dates = pd.concat([quarantine_dates, df_clean[invalid_date_mask]], ignore_index=True)\n",
    "        df_clean = df_clean[~invalid_date_mask].copy()\n",
    "\n",
    "    # Flag future & pre-2020 for business validation\n",
    "    current_year = datetime.now().year\n",
    "    df_clean['flag_future_date'] = df_clean[DATE_COL].dt.year > current_year\n",
    "    df_clean['flag_pre2020_date'] = df_clean[DATE_COL].dt.year < 2020\n",
    "\n",
    "    # Temporal columns for downstream transformations\n",
    "    df_clean['Year'] = df_clean[DATE_COL].dt.year\n",
    "    df_clean['Month'] = df_clean[DATE_COL].dt.month\n",
    "    df_clean['Day'] = df_clean[DATE_COL].dt.day\n",
    "    df_clean['DayOfWeek'] = df_clean[DATE_COL].dt.day_name()\n",
    "else:\n",
    "    df_clean['flag_future_date'] = False\n",
    "    df_clean['flag_pre2020_date'] = False\n",
    "\n",
    "# ---------------------------\n",
    "# 2) NUMERICS\n",
    "# ---------------------------\n",
    "# Negative flags\n",
    "for nc in [c for c in NUMERIC_COLS if c in df_clean.columns]:\n",
    "    df_clean[f'flag_negative_{nc}'] = df_clean[nc] < 0\n",
    "\n",
    "# Internal consistency: Total Spent ≈ Price × Quantity (only where all 3 non-null)\n",
    "if all(c in df_clean.columns for c in NUMERIC_COLS):\n",
    "    complete_num = df_clean[NUMERIC_COLS].notna().all(axis=1)\n",
    "    expected_total = df_clean.loc[complete_num, 'Price Per Unit'] * df_clean.loc[complete_num, 'Quantity']\n",
    "    discrep_mask = pd.Series(False, index=df_clean.index)\n",
    "    discrep_mask.loc[complete_num] = (expected_total - df_clean.loc[complete_num, 'Total Spent']).abs() > TOL\n",
    "    df_clean['flag_discrepancy_total'] = discrep_mask\n",
    "else:\n",
    "    df_clean['flag_discrepancy_total'] = False\n",
    "# --- PRE-REPAIR DIAGNOSTICS ---                                         # <<< NEW\n",
    "pre_dm = df_clean.get('flag_discount_mismatch', pd.Series(False, index=df_clean.index)).fillna(False)   # <<< NEW\n",
    "pre_dm_count = int(pre_dm.sum())                                                                            # <<< NEW\n",
    "pre_flag_cols = [c for c in df_clean.columns if c.startswith('flag_')]                                      # <<< NEW\n",
    "pre_flag_counts = df_clean[pre_flag_cols].sum().sort_values(ascending=False) if pre_flag_cols else None     # <<< NEW\n",
    "# Intelligent backfill when exactly one of the three is missing\n",
    "int_fill_actions = {}\n",
    "if all(c in df_clean.columns for c in NUMERIC_COLS):\n",
    "    # Fill Total Spent if Price & Quantity present\n",
    "    m_total = df_clean['Total Spent'].isna() & df_clean['Price Per Unit'].notna() & df_clean['Quantity'].notna()\n",
    "    df_clean.loc[m_total, 'Total Spent'] = df_clean.loc[m_total, 'Price Per Unit'] * df_clean.loc[m_total, 'Quantity']\n",
    "    int_fill_actions['totals_from_price_qty'] = int(m_total.sum())\n",
    "\n",
    "    # Fill Price Per Unit if Total & Quantity present (quantity != 0)\n",
    "    m_price = df_clean['Price Per Unit'].isna() & df_clean['Total Spent'].notna() & df_clean['Quantity'].notna() & (df_clean['Quantity'] != 0)\n",
    "    df_clean.loc[m_price, 'Price Per Unit'] = df_clean.loc[m_price, 'Total Spent'] / df_clean.loc[m_price, 'Quantity']\n",
    "    int_fill_actions['price_from_total_qty'] = int(m_price.sum())\n",
    "\n",
    "    # Fill Quantity if Total & Price present (price != 0)\n",
    "    m_qty = df_clean['Quantity'].isna() & df_clean['Total Spent'].notna() & df_clean['Price Per Unit'].notna() & (df_clean['Price Per Unit'] != 0)\n",
    "    df_clean.loc[m_qty, 'Quantity'] = df_clean.loc[m_qty, 'Total Spent'] / df_clean.loc[m_qty, 'Price Per Unit']\n",
    "    int_fill_actions['qty_from_total_price'] = int(m_qty.sum())\n",
    "\n",
    "# ---------------------------\n",
    "# 3) DISCOUNTS\n",
    "# ---------------------------\n",
    "# coerce_types already normalized 'Discount Applied' -> boolean/NaN\n",
    "# Ensure metric columns exist\n",
    "if 'Discount_Amount' not in df_clean.columns:\n",
    "    df_clean['Discount_Amount'] = 0.0\n",
    "if 'Discount_Percentage' not in df_clean.columns:\n",
    "    df_clean['Discount_Percentage'] = 0.0\n",
    "\n",
    "filling_actions = {}\n",
    "if all(c in df_clean.columns for c in NUMERIC_COLS):\n",
    "    if 'Discount Applied' in df_clean.columns:\n",
    "        # Infer discount where flag is NaN but math implies discount\n",
    "        missing_discounts = int(df_clean['Discount Applied'].isna().sum())\n",
    "        mask = df_clean['Discount Applied'].isna() & df_clean[NUMERIC_COLS].notna().all(axis=1)\n",
    "        exp_total = df_clean.loc[mask, 'Price Per Unit'] * df_clean.loc[mask, 'Quantity']\n",
    "        diff = (exp_total - df_clean.loc[mask, 'Total Spent'])\n",
    "        disc_mask = diff > TOL\n",
    "        no_disc_mask = ~disc_mask\n",
    "\n",
    "        df_clean.loc[mask & disc_mask, 'Discount Applied'] = True\n",
    "        df_clean.loc[mask & no_disc_mask, 'Discount Applied'] = False\n",
    "\n",
    "        df_clean.loc[mask & disc_mask, 'Discount_Amount'] = diff[disc_mask].values\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            df_clean.loc[mask & disc_mask, 'Discount_Percentage'] = np.where(\n",
    "                exp_total[disc_mask].values != 0,\n",
    "                (df_clean.loc[mask & disc_mask, 'Discount_Amount'] / exp_total[disc_mask].values) * 100,\n",
    "                0.0\n",
    "            )\n",
    "        filling_actions['discounts_inferred'] = int((mask & disc_mask).sum())\n",
    "    else:\n",
    "        missing_discounts = 0\n",
    "\n",
    "    # Compute for rows with Discount Applied == True (idempotent)\n",
    "    if 'Discount Applied' in df_clean.columns:\n",
    "        true_mask = df_clean['Discount Applied'] == True\n",
    "        exp_total_true = df_clean.loc[true_mask, 'Price Per Unit'] * df_clean.loc[true_mask, 'Quantity']\n",
    "        diff_true = (exp_total_true - df_clean.loc[true_mask, 'Total Spent']).clip(lower=0)\n",
    "        df_clean.loc[true_mask, 'Discount_Amount'] = diff_true.values\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            df_clean.loc[true_mask, 'Discount_Percentage'] = np.where(\n",
    "                exp_total_true.values != 0,\n",
    "                (df_clean.loc[true_mask, 'Discount_Amount'] / exp_total_true.values) * 100,\n",
    "                0.0\n",
    "            )\n",
    "\n",
    "        # Flag mismatches: boolean vs. math\n",
    "        df_clean['flag_discount_mismatch'] = False\n",
    "        mismatch_true = true_mask & (df_clean['Discount_Amount'] <= TOL)  # True but no discount by math\n",
    "        implied_disc_mask = (df_clean['Discount Applied'] == False) & df_clean[NUMERIC_COLS].notna().all(axis=1)\n",
    "        implied_exp = df_clean.loc[implied_disc_mask, 'Price Per Unit'] * df_clean.loc[implied_disc_mask, 'Quantity']\n",
    "        implied_disc_mask = implied_disc_mask & ((implied_exp - df_clean.loc[implied_disc_mask, 'Total Spent']) > TOL)\n",
    "        df_clean.loc[mismatch_true | implied_disc_mask, 'flag_discount_mismatch'] = True\n",
    "else:\n",
    "    df_clean['flag_discount_mismatch'] = False\n",
    "# --- Capture PRE-REPAIR diagnostics (BEFORE the repair block) ---\n",
    "# Basic overlap counts\n",
    "pre_dm = df_clean.get('flag_discount_mismatch', pd.Series(False, index=df_clean.index)).fillna(False)\n",
    "pre_disc = df_clean.get('flag_discrepancy_total', pd.Series(False, index=df_clean.index)).fillna(False)\n",
    "\n",
    "pre_dm_count = int(pre_dm.sum())\n",
    "pre_disc_count = int(pre_disc.sum())\n",
    "pre_overlap_both = int((pre_dm & pre_disc).sum())\n",
    "pre_only_dm = pre_dm_count - pre_overlap_both\n",
    "pre_only_disc = pre_disc_count - pre_overlap_both\n",
    "\n",
    "# Per-flag totals (any column that starts with 'flag_')\n",
    "pre_flag_cols = [c for c in df_clean.columns if c.startswith('flag_')]\n",
    "pre_flag_counts = (\n",
    "    df_clean[pre_flag_cols].sum().sort_values(ascending=False)\n",
    "    if pre_flag_cols else None\n",
    ")\n",
    "# ---------------------------\n",
    "# 3b) REPAIR DISCOUNT MISMATCH ROWS (make analysis-ready)\n",
    "# ---------------------------\n",
    "if 'flag_discount_mismatch' in df_clean.columns and all(c in df_clean.columns for c in NUMERIC_COLS):\n",
    "    dm = df_clean['flag_discount_mismatch'].fillna(False) & df_clean[NUMERIC_COLS].notna().all(axis=1)\n",
    "    fix_count = int(dm.sum())\n",
    "    if fix_count:\n",
    "        exp = df_clean.loc[dm, 'Price Per Unit'] * df_clean.loc[dm, 'Quantity']\n",
    "        diff = (exp - df_clean.loc[dm, 'Total Spent'])\n",
    "\n",
    "        as_disc = diff > TOL       # implied discount\n",
    "        as_nodisc = ~as_disc       # no discount implied\n",
    "\n",
    "        # Apply repaired values\n",
    "        df_clean.loc[dm & as_disc, 'Discount Applied'] = True\n",
    "        df_clean.loc[dm & as_disc, 'Discount_Amount'] = diff[as_disc].values\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            df_clean.loc[dm & as_disc, 'Discount_Percentage'] = np.where(\n",
    "                exp[as_disc].values != 0,\n",
    "                (df_clean.loc[dm & as_disc, 'Discount_Amount'] / exp[as_disc].values) * 100,\n",
    "                0.0\n",
    "            )\n",
    "\n",
    "        df_clean.loc[dm & as_nodisc, 'Discount Applied'] = False\n",
    "        df_clean.loc[dm & as_nodisc, ['Discount_Amount', 'Discount_Percentage']] = 0.0\n",
    "\n",
    "        # mismatch resolved -> clear the flag\n",
    "        df_clean.loc[dm, 'flag_discount_mismatch'] = False\n",
    "\n",
    "        print(f\"Repaired {fix_count:,} rows with discount mismatch by inferring discount from Price×Quantity vs Total.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) CATEGORICALS (standardize)\n",
    "# ---------------------------\n",
    "def _norm_str(s):\n",
    "    return str(s).strip().lower() if pd.notna(s) else s\n",
    "\n",
    "# Minimal controlled vocab examples — expand per your domain\n",
    "category_map = {\n",
    "    'electronics': 'Electronics',\n",
    "    'grocery': 'Grocery',\n",
    "    'clothing': 'Clothing',\n",
    "}\n",
    "payment_map = {\n",
    "    'credit': 'Credit Card',\n",
    "    'credit card': 'Credit Card',\n",
    "    'debit': 'Debit Card',\n",
    "    'debit card': 'Debit Card',\n",
    "    'cash': 'Cash',\n",
    "    'digital wallet': 'Digital Wallet',\n",
    "}\n",
    "location_map = {\n",
    "    'nyc': 'New York',\n",
    "    'new york': 'New York',\n",
    "    'sf': 'San Francisco',\n",
    "    'san francisco': 'San Francisco',\n",
    "}\n",
    "\n",
    "if 'Category' in df_clean.columns:\n",
    "    df_clean['Category_std'] = df_clean['Category'].map(lambda x: category_map.get(_norm_str(x), str(x).strip().title()))\n",
    "if 'Payment Method' in df_clean.columns:\n",
    "    df_clean['Payment Method_std'] = df_clean['Payment Method'].map(lambda x: payment_map.get(_norm_str(x), str(x).strip().title()))\n",
    "if 'Location' in df_clean.columns:\n",
    "    df_clean['Location_std'] = df_clean['Location'].map(lambda x: location_map.get(_norm_str(x), str(x).strip().title()))\n",
    "\n",
    "# ---------------------------\n",
    "# 5) DUPLICATES\n",
    "# ---------------------------\n",
    "removed_exact_dups = int(df_clean.duplicated().sum())\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "if KEY_COL in df_clean.columns:\n",
    "    df_clean['flag_txn_duplicate'] = df_clean.duplicated(subset=[KEY_COL], keep='first')\n",
    "else:\n",
    "    df_clean['flag_txn_duplicate'] = False\n",
    "\n",
    "# ---------------------------\n",
    "# Final splits (analysis-ready vs QA)\n",
    "# ---------------------------\n",
    "# Build flag lists AFTER all flags/repairs\n",
    "hard_flags = [\n",
    "    'flag_txn_duplicate',        # corrupt key\n",
    "    'flag_discrepancy_total',    # core arithmetic inconsistency\n",
    "] + [c for c in df_clean.columns if c.startswith('flag_negative_')]  # adjust per returns policy\n",
    "\n",
    "soft_flags = [\n",
    "    'flag_discount_mismatch',    # mostly cleared by repair step\n",
    "    'flag_future_date',\n",
    "    'flag_pre2020_date',\n",
    "]\n",
    "\n",
    "# Masks\n",
    "no_hard_flags_mask = (~pd.concat([df_clean[c] for c in hard_flags], axis=1).any(axis=1)) if hard_flags else pd.Series(True, index=df_clean.index)\n",
    "critical_columns = ['Item', 'Price Per Unit', 'Quantity', 'Total Spent']\n",
    "present_critical = [c for c in critical_columns if c in df_clean.columns]\n",
    "complete_mask = df_clean[present_critical].notna().all(axis=1) if present_critical else pd.Series(False, index=df_clean.index)\n",
    "\n",
    "analysis_ready_mask = complete_mask & no_hard_flags_mask\n",
    "df_final_complete = df_clean[analysis_ready_mask].copy()\n",
    "df_final_incomplete = df_clean[~analysis_ready_mask].copy()\n",
    "\n",
    "# --- Drop flag columns for analysis-ready & full-cleaned outputs ---\n",
    "flag_cols = [c for c in df_clean.columns if c.startswith('flag_')]\n",
    "df_final_complete_noflags = df_final_complete.drop(columns=flag_cols, errors='ignore')\n",
    "df_clean_noflags = df_clean.drop(columns=flag_cols, errors='ignore')\n",
    "\n",
    "# --- POST-repair diagnostics ---\n",
    "post_dm = df_clean.get('flag_discount_mismatch', pd.Series(False, index=df_clean.index)).fillna(False)\n",
    "post_disc = df_clean.get('flag_discrepancy_total', pd.Series(False, index=df_clean.index)).fillna(False)\n",
    "\n",
    "post_dm_count = int(post_dm.sum())\n",
    "post_disc_count = int(post_disc.sum())\n",
    "post_overlap_both = int((post_dm & post_disc).sum())\n",
    "post_only_dm = post_dm_count - post_overlap_both\n",
    "post_only_disc = post_disc_count - post_overlap_both\n",
    "\n",
    "post_flag_cols = [c for c in df_clean.columns if c.startswith('flag_')]\n",
    "post_flag_counts = (\n",
    "    df_clean[post_flag_cols].sum().sort_values(ascending=False)\n",
    "    if post_flag_cols else None\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# End Summary\n",
    "# ---------------------------\n",
    "print(\"\\n=== CLEANING SUMMARY ===\")\n",
    "print(f\"Original rows:                    {initial_records:,}\")\n",
    "print(f\"After exact-dup drop:             {len(df_clean):,} (removed {removed_exact_dups:,})\")\n",
    "print(f\"Analysis-ready rows (post-repair): {len(df_final_complete):,}\")\n",
    "print(f\"Incomplete/QA rows (post-repair):  {len(df_final_incomplete):,}\")\n",
    "print(\"Intelligent fill:\", int_fill_actions)\n",
    "\n",
    "\n",
    "# Flag counts (pre/post)\n",
    "if pre_flag_counts is not None:\n",
    "    print(\"\\n[Pre-repair] Rows flagged by each rule:\")\n",
    "    print(pre_flag_counts.rename(lambda c: c.replace('flag_', '')))\n",
    "if post_flag_counts is not None:\n",
    "    print(\"\\n[Post-repair] Rows flagged by each rule:\")\n",
    "    print(post_flag_counts.rename(lambda c: c.replace('flag_', '')))\n",
    "\n",
    "# Improvements summary\n",
    "resolved_mismatches = pre_dm_count - post_dm_count\n",
    "resolved_pct = (resolved_mismatches / pre_dm_count * 100) if pre_dm_count else 0.0\n",
    "print(\"\\n=== Improvements ===\")\n",
    "print(f\"Discount mismatch rows repaired: {resolved_mismatches:,} of {pre_dm_count:,} \"\n",
    "      f\"({resolved_pct:.1f}%) — via inferred discount from Price×Quantity vs Total.\")\n",
    "print(f\"Rows directly updated in repair step: {fix_count:,} (fields normalized: \"\n",
    "      f\"'Discount Applied', 'Discount_Amount', 'Discount_Percentage').\")\n",
    "\n",
    "# Report flag removal for outputs\n",
    "print(f\"\\nFlag columns removed from analysis-ready/full-cleaned outputs: {flag_cols}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aebf31b-a286-4567-9f25-ee7426299e19",
   "metadata": {},
   "source": [
    "## Reflections on Data Quality Checks: “Strict by Design”\n",
    "\n",
    "Our cleaning pass was intentionally **watchful**: we tested for date anomalies, negative numerics, arithmetic discrepancies, discount mismatches, duplicates, and categorical inconsistencies. The post-run metrics show many flags at **zero** and 4,019 **discount mismatches** fully repaired by inference (Price×Quantity vs Total). That’s not wasted work—it’s **assurance**.\n",
    "\n",
    "### Why “over-checking” is valuable even when most flags are zero\n",
    "- **Proves absence, not assumption**: Zero counts mean we *verified* those risks aren’t present in this batch. That’s stronger than assuming they don’t exist.\n",
    "- **Guardrails for future drift**: Data pipelines face schema changes, vendor updates, and human entry error. These checks act as tripwires—quiet today, but ready to catch tomorrow’s anomalies.\n",
    "- **Auditability & reproducibility**: Clear flags and a repair log create a defensible record for stakeholders (finance, ops, compliance) of what we validated and when.\n",
    "- **Targeted fixes where it matters**: The discount logic identified 4,019 rows and **repaired them deterministically**, improving analysis readiness without blanket imputation.\n",
    "- **Business trust**: Downstream analyses (margins, promos, mix) depend on consistent price/quantity/total relationships. Validating and aligning these builds confidence in every KPI built on top.\n",
    "\n",
    "### What the results imply about this dataset\n",
    "- **Discounts were the primary friction point**, and our inference strategy resolved them completely, aligning math with semantics (`Discount Applied`, `Discount_Amount`, `%`).\n",
    "- **Other risk vectors are clean (today)**: No systemic negatives, date anomalies, or arithmetic discrepancies. That’s a strong indicator of source stability.\n",
    "- **Incomplete rows remain for QA not because we’re punitive**, but because we separate “analysis-ready” from “needs-clarification,” preventing silent data leakage into metrics.\n",
    "\n",
    "### How this helps downstream (T & L)\n",
    "- **Transformation-ready inputs**: With repaired discounts and clean numerics, aggregated facts (e.g., revenue by item/location/date) won’t be biased by hidden inconsistencies.\n",
    "- **Reliable dimensions**: Standardized categoricals (`*_std`) make joins stable and dashboard slice-and-dice consistent.\n",
    "- **Sustainable operations**: The same checks can run on new drops; zero today becomes signal tomorrow if something breaks upstream.\n",
    "\n",
    "> **Bottom line:** Even when most checks “do nothing,” they deliver *proof of integrity*. The one area that needed attention—discounts—was fixed in a transparent, reproducible way, lifting **11,362** rows into analysis-ready with confidence and leaving a clear QA trail for the rest.\n",
    ">\n",
    ">  **Editors Note:** Additionally, this data set is from a simulated kaggle download so even though it is \"messy\" it is all messy in the exact same way unlike a real dataset. All rows that didnt have price data, also failed to have an item SKU. This caused our 609 rows where we repaired price data to ultimately still be excluded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f4963",
   "metadata": {},
   "source": [
    "## 4) Save and Inspect cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179bd303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Cleaning summary JSON:          C:\\Users\\matth\\etl_online_retail_project\\data\\artifacts\\cleaning_summary.json\n",
      "Saved:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Item</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "      <th>Discount Applied</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Discount_Amount</th>\n",
       "      <th>Discount_Percentage</th>\n",
       "      <th>Category_std</th>\n",
       "      <th>Payment Method_std</th>\n",
       "      <th>Location_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_6867343</td>\n",
       "      <td>CUST_09</td>\n",
       "      <td>Patisserie</td>\n",
       "      <td>Item_10_PAT</td>\n",
       "      <td>18.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>False</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Patisserie</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_3731986</td>\n",
       "      <td>CUST_22</td>\n",
       "      <td>Milk Products</td>\n",
       "      <td>Item_17_MILK</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>False</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Milk Products</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_9303719</td>\n",
       "      <td>CUST_02</td>\n",
       "      <td>Butchers</td>\n",
       "      <td>Item_12_BUT</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Butchers</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_9458126</td>\n",
       "      <td>CUST_06</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Item_16_BEV</td>\n",
       "      <td>27.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>247.5</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_4575373</td>\n",
       "      <td>CUST_05</td>\n",
       "      <td>Food</td>\n",
       "      <td>Item_6_FOOD</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Food</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXN_7482416</td>\n",
       "      <td>CUST_09</td>\n",
       "      <td>Patisserie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>False</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Patisserie</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TXN_3652209</td>\n",
       "      <td>CUST_07</td>\n",
       "      <td>Food</td>\n",
       "      <td>Item_1_FOOD</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-10</td>\n",
       "      <td>False</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Food</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TXN_1372952</td>\n",
       "      <td>CUST_21</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>True</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TXN_9728486</td>\n",
       "      <td>CUST_23</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Item_16_FUR</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>False</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TXN_2722661</td>\n",
       "      <td>CUST_25</td>\n",
       "      <td>Butchers</td>\n",
       "      <td>Item_22_BUT</td>\n",
       "      <td>36.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Online</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>False</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Butchers</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Online</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID Customer ID       Category          Item  Price Per Unit  \\\n",
       "0    TXN_6867343     CUST_09     Patisserie   Item_10_PAT            18.5   \n",
       "1    TXN_3731986     CUST_22  Milk Products  Item_17_MILK            29.0   \n",
       "2    TXN_9303719     CUST_02       Butchers   Item_12_BUT            21.5   \n",
       "3    TXN_9458126     CUST_06      Beverages   Item_16_BEV            27.5   \n",
       "4    TXN_4575373     CUST_05           Food   Item_6_FOOD            12.5   \n",
       "5    TXN_7482416     CUST_09     Patisserie           NaN            20.0   \n",
       "6    TXN_3652209     CUST_07           Food   Item_1_FOOD             5.0   \n",
       "7    TXN_1372952     CUST_21      Furniture           NaN            33.5   \n",
       "8    TXN_9728486     CUST_23      Furniture   Item_16_FUR            27.5   \n",
       "9    TXN_2722661     CUST_25       Butchers   Item_22_BUT            36.5   \n",
       "\n",
       "   Quantity  Total Spent  Payment Method  Location Transaction Date  \\\n",
       "0      10.0        185.0  Digital Wallet    Online       2024-04-08   \n",
       "1       9.0        261.0  Digital Wallet    Online       2023-07-23   \n",
       "2       2.0         43.0     Credit Card    Online       2022-10-05   \n",
       "3       9.0        247.5     Credit Card    Online       2022-05-07   \n",
       "4       7.0         87.5  Digital Wallet    Online       2022-10-02   \n",
       "5      10.0        200.0     Credit Card    Online       2023-11-30   \n",
       "6       8.0         40.0     Credit Card  In-store       2023-06-10   \n",
       "7       NaN          NaN  Digital Wallet  In-store       2024-04-02   \n",
       "8       1.0         27.5     Credit Card  In-store       2023-04-26   \n",
       "9       3.0        109.5            Cash    Online       2024-03-14   \n",
       "\n",
       "  Discount Applied  Year  Month  Day  DayOfWeek  Discount_Amount  \\\n",
       "0            False  2024      4    8     Monday              0.0   \n",
       "1            False  2023      7   23     Sunday              0.0   \n",
       "2            False  2022     10    5  Wednesday              0.0   \n",
       "3            False  2022      5    7   Saturday              0.0   \n",
       "4            False  2022     10    2     Sunday              0.0   \n",
       "5            False  2023     11   30   Thursday              0.0   \n",
       "6            False  2023      6   10   Saturday              0.0   \n",
       "7             True  2024      4    2    Tuesday              NaN   \n",
       "8            False  2023      4   26  Wednesday              0.0   \n",
       "9            False  2024      3   14   Thursday              0.0   \n",
       "\n",
       "   Discount_Percentage   Category_std Payment Method_std Location_std  \n",
       "0                  0.0     Patisserie     Digital Wallet       Online  \n",
       "1                  0.0  Milk Products     Digital Wallet       Online  \n",
       "2                  0.0       Butchers        Credit Card       Online  \n",
       "3                  0.0      Beverages        Credit Card       Online  \n",
       "4                  0.0           Food     Digital Wallet       Online  \n",
       "5                  0.0     Patisserie        Credit Card       Online  \n",
       "6                  0.0           Food        Credit Card     In-Store  \n",
       "7                  NaN      Furniture     Digital Wallet     In-Store  \n",
       "8                  0.0      Furniture        Credit Card     In-Store  \n",
       "9                  0.0       Butchers               Cash       Online  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "complete_data_path = os.path.join(DATA_DIR, 'cleanedCompleteForDataAnalysis.csv')\n",
    "incomplete_data_path = os.path.join(DATA_DIR, 'cleanedForDataQualityAnalysis.csv')\n",
    "full_cleaned_path = os.path.join(DATA_DIR, 'cleaned_retail_store_sales.csv')\n",
    "\n",
    "df_final_complete.to_csv(complete_data_path, index=False)\n",
    "df_final_incomplete.to_csv(incomplete_data_path, index=False)\n",
    "df_clean.to_csv(full_cleaned_path, index=False)\n",
    "\n",
    "cleaning_summary = {\n",
    "    'cleaning_date': datetime.now().isoformat(),\n",
    "    'records': {\n",
    "        'original': initial_records,\n",
    "        'after_exact_dup_drop': len(df_clean),\n",
    "        'removed_exact_dups': removed_exact_dups,\n",
    "        'analysis_ready': len(df_final_complete),\n",
    "        'incomplete_or_QA': len(df_final_incomplete)\n",
    "    },\n",
    "    'cleaning_actions': {\n",
    "        'invalid_dates_removed': int(invalid_dates) if 'invalid_dates' in locals() else 0,     # <<< CHANGED (guard)\n",
    "        'missing_discounts_seen': int(missing_discounts) if 'missing_discounts' in locals() else 0,\n",
    "        'intelligent_fill': int_fill_actions,\n",
    "        'rows_repaired_in_discount_fix': fix_count,                                            # <<< NEW\n",
    "        'fields_normalized': ['Discount Applied', 'Discount_Amount', 'Discount_Percentage']    # <<< NEW\n",
    "    },\n",
    "    'discount_diagnostics': {                                                                  # <<< NEW\n",
    "        'pre_repair': {\n",
    "            'mismatch_total': pre_dm_count,\n",
    "            'flag_counts': pre_flag_counts.to_dict() if pre_flag_counts is not None else {}\n",
    "        },\n",
    "        'post_repair': {\n",
    "            'mismatch_total': post_dm_count,\n",
    "            'flag_counts': post_flag_counts.to_dict() if post_flag_counts is not None else {}\n",
    "        },\n",
    "        'improvements': {\n",
    "            'resolved_mismatches': (pre_dm_count - post_dm_count),\n",
    "            'percent_resolved': (100.0 * (pre_dm_count - post_dm_count) / pre_dm_count) if pre_dm_count else 0.0\n",
    "        }\n",
    "    },\n",
    "    'notes': {\n",
    "        'flags_dropped_in_outputs': [c for c in flag_cols],                                    # <<< NEW\n",
    "        'outputs': {\n",
    "            'complete_no_flags': os.path.basename(complete_data_path),\n",
    "            'incomplete_with_flags': os.path.basename(incomplete_data_path),\n",
    "            'full_cleaned_no_flags': os.path.basename(full_cleaned_path)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "clean_json_path = save_json(cleaning_summary, 'cleaning_summary.json')\n",
    "print(f\" - Cleaning summary JSON:          {clean_json_path}\")                                 # <<< NEW\n",
    "\n",
    "\n",
    "clean_json_path = save_json(cleaning_summary, 'cleaning_summary.json')\n",
    "\n",
    "print('Saved:')\n",
    "#print(' -', complete_data_path)\n",
    "#print(' -', incomplete_data_path)\n",
    "#print(' -', full_cleaned_path)\n",
    "#print(' -', clean_json_path)\n",
    "\n",
    "df_clean_noflags.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac4cca-6e0e-45f2-9516-12de538c7d03",
   "metadata": {},
   "source": [
    "## 5) SQL Schema Design & ETL to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b387bc-9a13-41a3-818b-e8cb4985d174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema created in sales.db\n",
      "Staging tables loaded: stg_sales_raw, stg_txn_header\n",
      "Dimensions populated.\n",
      "Transaction headers inserted.\n",
      "Transaction items inserted.\n",
      "Validation and Display below.\n",
      "\n",
      "--- counts ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customers</th>\n",
       "      <th>categories</th>\n",
       "      <th>items</th>\n",
       "      <th>payment_methods</th>\n",
       "      <th>channels</th>\n",
       "      <th>transactions</th>\n",
       "      <th>transaction_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12575</td>\n",
       "      <td>11362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customers  categories  items  payment_methods  channels  transactions  \\\n",
       "0         25           8    200                3         2         12575   \n",
       "\n",
       "   transaction_items  \n",
       "0              11362  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- sample_txn ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_id</th>\n",
       "      <th>txn_code</th>\n",
       "      <th>customer</th>\n",
       "      <th>txn_ts</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dow</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>channel</th>\n",
       "      <th>txn_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>722</td>\n",
       "      <td>TXN_1505827</td>\n",
       "      <td>CUST_13</td>\n",
       "      <td>2025-01-18 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>949</td>\n",
       "      <td>TXN_1661883</td>\n",
       "      <td>CUST_04</td>\n",
       "      <td>2025-01-18 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1099</td>\n",
       "      <td>TXN_1777313</td>\n",
       "      <td>CUST_07</td>\n",
       "      <td>2025-01-18 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6012</td>\n",
       "      <td>TXN_5321918</td>\n",
       "      <td>CUST_24</td>\n",
       "      <td>2025-01-18 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6577</td>\n",
       "      <td>TXN_5709336</td>\n",
       "      <td>CUST_10</td>\n",
       "      <td>2025-01-18 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6704</td>\n",
       "      <td>TXN_5804265</td>\n",
       "      <td>CUST_11</td>\n",
       "      <td>2025-01-18 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Online</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6841</td>\n",
       "      <td>TXN_5907338</td>\n",
       "      <td>CUST_25</td>\n",
       "      <td>2025-01-18 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7500</td>\n",
       "      <td>TXN_6383632</td>\n",
       "      <td>CUST_12</td>\n",
       "      <td>2025-01-18 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8867</td>\n",
       "      <td>TXN_7369318</td>\n",
       "      <td>CUST_01</td>\n",
       "      <td>2025-01-18 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>TXN_1011669</td>\n",
       "      <td>CUST_14</td>\n",
       "      <td>2025-01-17 00:00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Online</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   txn_id     txn_code customer               txn_ts  year  month  day  dow  \\\n",
       "0     722  TXN_1505827  CUST_13  2025-01-18 00:00:00  2025      1   18    6   \n",
       "1     949  TXN_1661883  CUST_04  2025-01-18 00:00:00  2025      1   18    6   \n",
       "2    1099  TXN_1777313  CUST_07  2025-01-18 00:00:00  2025      1   18    6   \n",
       "3    6012  TXN_5321918  CUST_24  2025-01-18 00:00:00  2025      1   18    6   \n",
       "4    6577  TXN_5709336  CUST_10  2025-01-18 00:00:00  2025      1   18    6   \n",
       "5    6704  TXN_5804265  CUST_11  2025-01-18 00:00:00  2025      1   18    6   \n",
       "6    6841  TXN_5907338  CUST_25  2025-01-18 00:00:00  2025      1   18    6   \n",
       "7    7500  TXN_6383632  CUST_12  2025-01-18 00:00:00  2025      1   18    6   \n",
       "8    8867  TXN_7369318  CUST_01  2025-01-18 00:00:00  2025      1   18    6   \n",
       "9      19  TXN_1011669  CUST_14  2025-01-17 00:00:00  2025      1   17    5   \n",
       "\n",
       "   payment_method   channel  txn_total  \n",
       "0  Digital Wallet    Online        NaN  \n",
       "1            Cash  In-Store      261.0  \n",
       "2     Credit Card    Online        NaN  \n",
       "3     Credit Card  In-Store       62.5  \n",
       "4     Credit Card  In-Store       19.0  \n",
       "5  Digital Wallet    Online       67.0  \n",
       "6            Cash  In-Store      342.0  \n",
       "7            Cash  In-Store       70.0  \n",
       "8     Credit Card    Online      100.0  \n",
       "9     Credit Card    Online      184.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- top_items ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "      <th>item_code</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Furniture</td>\n",
       "      <td>Item_25_FUR</td>\n",
       "      <td>25256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electric Household Essentials</td>\n",
       "      <td>Item_25_EHE</td>\n",
       "      <td>23083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Butchers</td>\n",
       "      <td>Item_25_BUT</td>\n",
       "      <td>21894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Furniture</td>\n",
       "      <td>Item_24_FUR</td>\n",
       "      <td>21172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food</td>\n",
       "      <td>Item_25_FOOD</td>\n",
       "      <td>20541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Butchers</td>\n",
       "      <td>Item_22_BUT</td>\n",
       "      <td>19710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Butchers</td>\n",
       "      <td>Item_23_BUT</td>\n",
       "      <td>19114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Butchers</td>\n",
       "      <td>Item_20_BUT</td>\n",
       "      <td>18860.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Milk Products</td>\n",
       "      <td>Item_19_MILK</td>\n",
       "      <td>18848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Electric Household Essentials</td>\n",
       "      <td>Item_23_EHE</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   category_name     item_code  revenue\n",
       "0                      Furniture   Item_25_FUR  25256.0\n",
       "1  Electric Household Essentials   Item_25_EHE  23083.0\n",
       "2                       Butchers   Item_25_BUT  21894.0\n",
       "3                      Furniture   Item_24_FUR  21172.0\n",
       "4                           Food  Item_25_FOOD  20541.0\n",
       "5                       Butchers   Item_22_BUT  19710.0\n",
       "6                       Butchers   Item_23_BUT  19114.0\n",
       "7                       Butchers   Item_20_BUT  18860.5\n",
       "8                  Milk Products  Item_19_MILK  18848.0\n",
       "9  Electric Household Essentials   Item_23_EHE  18468.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlite3\n",
    "DB_PATH = \"sales.db\"\n",
    "df = df_clean_noflags\n",
    "\n",
    "# Prefer standardized columns if present; otherwise use originals.\n",
    "cat_col   = 'Category_std' if 'Category_std' in df.columns else 'Category'\n",
    "pm_col    = 'Payment Method_std' if 'Payment Method_std' in df.columns else 'Payment Method'\n",
    "loc_col   = 'Location_std' if 'Location_std' in df.columns else 'Location'\n",
    "item_col  = 'Item'  # item_std not provided in sample; keep as-is\n",
    "\n",
    "# Make a shallow copy with uniform column names for staging\n",
    "stg = df.rename(columns={\n",
    "    'Transaction ID':'transaction_id',\n",
    "    'Customer ID':'customer_id',\n",
    "    cat_col:'category',\n",
    "    item_col:'item',\n",
    "    'Price Per Unit':'price_per_unit',\n",
    "    'Quantity':'quantity',\n",
    "    'Total Spent':'total_spent',\n",
    "    pm_col:'payment_method',\n",
    "    loc_col:'location',\n",
    "    'Transaction Date':'transaction_date',\n",
    "    'Discount Applied':'discount_applied',\n",
    "    'Discount_Amount':'discount_amount',\n",
    "    'Discount_Percentage':'discount_percentage'\n",
    "}).copy()\n",
    "\n",
    "# Ensure expected columns exist (create if not)\n",
    "for col, default in [\n",
    "    ('discount_amount', 0.0),\n",
    "    ('discount_percentage', 0.0),\n",
    "]:\n",
    "    if col not in stg.columns:\n",
    "        stg[col] = default\n",
    "\n",
    "# Normalize channel and booleans on the pandas side for consistency\n",
    "stg['location'] = stg['location'].apply(norm_channel)\n",
    "stg['discount_applied'] = stg['discount_applied'].apply(boolish_to_int)\n",
    "\n",
    "# Parse dates to datetime (errors='coerce' puts bad dates as NaT, which we can quarantine if needed)\n",
    "stg['transaction_date'] = pd.to_datetime(stg['transaction_date'], errors='coerce').dt.date\n",
    "\n",
    "# Create a header staging table by deduping on transaction_id\n",
    "# Keep the *last* non-null row per transaction (sortable by date then index)\n",
    "stg_sorted = stg.sort_values(['transaction_id', 'transaction_date'], kind='mergesort')\n",
    "header_cols = ['transaction_id','customer_id','payment_method','location','transaction_date','discount_applied']\n",
    "stg_txn_header = (\n",
    "    stg_sorted\n",
    "    .drop_duplicates(subset=['transaction_id'], keep='last')[header_cols]\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Enrich header with calendar parts for convenience\n",
    "stg_txn_header['transaction_date'] = pd.to_datetime(stg_txn_header['transaction_date'], errors='coerce')\n",
    "stg_txn_header['year']  = stg_txn_header['transaction_date'].dt.year.astype('Int64')\n",
    "stg_txn_header['month'] = stg_txn_header['transaction_date'].dt.month.astype('Int64')\n",
    "stg_txn_header['day']   = stg_txn_header['transaction_date'].dt.day.astype('Int64')\n",
    "# SQLite weekday: 0=Sunday in strftime('%w'); we’ll compute in SQL later if needed\n",
    "\n",
    "\n",
    "con = sqlite3.connect(DB_PATH)\n",
    "cur = con.cursor()\n",
    "cur.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "\n",
    "ddl = \"\"\"\n",
    "-- Lookups\n",
    "CREATE TABLE IF NOT EXISTS customers (\n",
    "  customer_id        INTEGER PRIMARY KEY,\n",
    "  customer_code      TEXT NOT NULL UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS categories (\n",
    "  category_id        INTEGER PRIMARY KEY,\n",
    "  category_name      TEXT NOT NULL UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS items (\n",
    "  item_id            INTEGER PRIMARY KEY,\n",
    "  item_code          TEXT NOT NULL UNIQUE,\n",
    "  category_id        INTEGER NOT NULL,\n",
    "  FOREIGN KEY (category_id) REFERENCES categories(category_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS payment_methods (\n",
    "  payment_method_id  INTEGER PRIMARY KEY,\n",
    "  method_name        TEXT NOT NULL UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS channels (\n",
    "  channel_id         INTEGER PRIMARY KEY,\n",
    "  channel_name       TEXT NOT NULL UNIQUE\n",
    ");\n",
    "\n",
    "-- Transactions (header)\n",
    "CREATE TABLE IF NOT EXISTS transactions (\n",
    "  txn_id             INTEGER PRIMARY KEY,\n",
    "  txn_code           TEXT NOT NULL UNIQUE,\n",
    "  customer_id        INTEGER NOT NULL,\n",
    "  payment_method_id  INTEGER NOT NULL,\n",
    "  channel_id         INTEGER NOT NULL,\n",
    "  txn_ts             TEXT NOT NULL,               -- ISO8601 date or datetime\n",
    "  discount_applied   INTEGER NOT NULL DEFAULT 0,\n",
    "  year               INTEGER,\n",
    "  month              INTEGER,\n",
    "  day                INTEGER,\n",
    "  dow                INTEGER,                     -- 0=Sunday via strftime('%w')\n",
    "\n",
    "  FOREIGN KEY (customer_id)       REFERENCES customers(customer_id),\n",
    "  FOREIGN KEY (payment_method_id) REFERENCES payment_methods(payment_method_id),\n",
    "  FOREIGN KEY (channel_id)        REFERENCES channels(channel_id)\n",
    ");\n",
    "\n",
    "-- Transaction items (detail)\n",
    "CREATE TABLE IF NOT EXISTS transaction_items (\n",
    "  txn_item_id        INTEGER PRIMARY KEY,\n",
    "  txn_id             INTEGER NOT NULL,\n",
    "  item_id            INTEGER NOT NULL,\n",
    "  price_per_unit_c   INTEGER NOT NULL CHECK (price_per_unit_c >= 0),\n",
    "  quantity           REAL    NOT NULL CHECK (quantity > 0),\n",
    "  discount_amount_c  INTEGER NOT NULL DEFAULT 0 CHECK (discount_amount_c >= 0),\n",
    "  discount_pct       REAL    NOT NULL DEFAULT 0 CHECK (discount_pct >= 0 AND discount_pct <= 100),\n",
    "  line_total_c       INTEGER NOT NULL CHECK (line_total_c >= 0),\n",
    "  FOREIGN KEY (txn_id)  REFERENCES transactions(txn_id) ON DELETE CASCADE,\n",
    "  FOREIGN KEY (item_id) REFERENCES items(item_id)\n",
    ");\n",
    "\n",
    "-- Integrity triggers (line_total matches computed)\n",
    "CREATE TRIGGER IF NOT EXISTS trg_ti_check_before_insert\n",
    "BEFORE INSERT ON transaction_items\n",
    "FOR EACH ROW\n",
    "BEGIN\n",
    "  SELECT\n",
    "    CASE\n",
    "      WHEN NEW.line_total_c !=\n",
    "           CAST(ROUND(NEW.price_per_unit_c * NEW.quantity) AS INTEGER)\n",
    "           - NEW.discount_amount_c\n",
    "           - CAST(ROUND((NEW.discount_pct/100.0) * NEW.price_per_unit_c * NEW.quantity) AS INTEGER)\n",
    "      THEN RAISE(ABORT, 'line_total_c does not match computed total')\n",
    "    END;\n",
    "END;\n",
    "\n",
    "CREATE TRIGGER IF NOT EXISTS trg_ti_check_before_update\n",
    "BEFORE UPDATE ON transaction_items\n",
    "FOR EACH ROW\n",
    "BEGIN\n",
    "  SELECT\n",
    "    CASE\n",
    "      WHEN NEW.line_total_c !=\n",
    "           CAST(ROUND(NEW.price_per_unit_c * NEW.quantity) AS INTEGER)\n",
    "           - NEW.discount_amount_c\n",
    "           - CAST(ROUND((NEW.discount_pct/100.0) * NEW.price_per_unit_c * NEW.quantity) AS INTEGER)\n",
    "      THEN RAISE(ABORT, 'line_total_c does not match computed total')\n",
    "    END;\n",
    "END;\n",
    "\n",
    "-- Indexes\n",
    "CREATE INDEX IF NOT EXISTS idx_txn_ts                 ON transactions(txn_ts);\n",
    "CREATE INDEX IF NOT EXISTS idx_txn_customer           ON transactions(customer_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_txn_payment_channel    ON transactions(payment_method_id, channel_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_ti_txn                 ON transaction_items(txn_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_ti_item                ON transaction_items(item_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_items_category         ON items(category_id);\n",
    "\n",
    "-- Views (human-friendly dollars)\n",
    "CREATE VIEW IF NOT EXISTS v_transaction_items AS\n",
    "SELECT\n",
    "  ti.txn_item_id,\n",
    "  t.txn_code,\n",
    "  i.item_code,\n",
    "  c.category_name,\n",
    "  (ti.price_per_unit_c / 100.0) AS price_per_unit,\n",
    "  ti.quantity,\n",
    "  (ti.discount_amount_c / 100.0) AS discount_amount,\n",
    "  ti.discount_pct,\n",
    "  (ti.line_total_c / 100.0)     AS line_total,\n",
    "  t.txn_ts,\n",
    "  pm.method_name   AS payment_method,\n",
    "  ch.channel_name  AS channel,\n",
    "  cust.customer_code AS customer\n",
    "FROM transaction_items ti\n",
    "JOIN transactions t     ON t.txn_id = ti.txn_id\n",
    "JOIN items i            ON i.item_id = ti.item_id\n",
    "JOIN categories c       ON c.category_id = i.category_id\n",
    "JOIN payment_methods pm ON pm.payment_method_id = t.payment_method_id\n",
    "JOIN channels ch        ON ch.channel_id = t.channel_id\n",
    "JOIN customers cust     ON cust.customer_id = t.customer_id;\n",
    "\n",
    "CREATE VIEW IF NOT EXISTS v_transactions AS\n",
    "SELECT\n",
    "  t.txn_id,\n",
    "  t.txn_code,\n",
    "  cust.customer_code AS customer,\n",
    "  t.txn_ts,\n",
    "  t.year, t.month, t.day, t.dow,\n",
    "  pm.method_name     AS payment_method,\n",
    "  ch.channel_name    AS channel,\n",
    "  SUM(ti.line_total_c)/100.0 AS txn_total\n",
    "FROM transactions t\n",
    "JOIN customers cust     ON cust.customer_id = t.customer_id\n",
    "JOIN payment_methods pm ON pm.payment_method_id = t.payment_method_id\n",
    "JOIN channels ch        ON ch.channel_id = t.channel_id\n",
    "LEFT JOIN transaction_items ti ON ti.txn_id = t.txn_id\n",
    "GROUP BY t.txn_id;\n",
    "\"\"\"\n",
    "cur.executescript(ddl)\n",
    "con.commit()\n",
    "print(\"Schema created in\", DB_PATH)\n",
    "stg_sales_raw_cols = [\n",
    "    'transaction_id','customer_id','category','item',\n",
    "    'price_per_unit','quantity','total_spent',\n",
    "    'payment_method','location','transaction_date',\n",
    "    'discount_applied','discount_amount','discount_percentage'\n",
    "]\n",
    "stg_to_sql = stg[stg_sales_raw_cols].copy()\n",
    "\n",
    "# SQLite likes plain strings for dates; keep ISO format\n",
    "stg_to_sql['transaction_date'] = pd.to_datetime(stg_to_sql['transaction_date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Write/replace staging tables\n",
    "stg_to_sql.to_sql('stg_sales_raw', con, if_exists='replace', index=False)\n",
    "stg_txn_header.to_sql('stg_txn_header', con, if_exists='replace', index=False)\n",
    "print(\"Staging tables loaded: stg_sales_raw, stg_txn_header\")\n",
    "#Populate dimension tables (INSERT OR IGNORE)\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.executescript(\"\"\"\n",
    "INSERT OR IGNORE INTO customers (customer_code)\n",
    "SELECT DISTINCT customer_id FROM stg_txn_header WHERE customer_id IS NOT NULL;\n",
    "\n",
    "INSERT OR IGNORE INTO categories (category_name)\n",
    "SELECT DISTINCT category FROM stg_sales_raw WHERE category IS NOT NULL;\n",
    "\n",
    "INSERT OR IGNORE INTO payment_methods (method_name)\n",
    "SELECT DISTINCT payment_method FROM stg_sales_raw WHERE payment_method IS NOT NULL;\n",
    "\n",
    "INSERT OR IGNORE INTO channels (channel_name)\n",
    "SELECT DISTINCT location FROM stg_sales_raw WHERE location IS NOT NULL;\n",
    "\"\"\")\n",
    "\n",
    "# Items depend on category_id; do with a join\n",
    "cur.executescript(\"\"\"\n",
    "INSERT OR IGNORE INTO items (item_code, category_id)\n",
    "SELECT DISTINCT s.item,\n",
    "       c.category_id\n",
    "FROM stg_sales_raw s\n",
    "JOIN categories c ON c.category_name = s.category\n",
    "WHERE s.item IS NOT NULL;\n",
    "\"\"\")\n",
    "\n",
    "con.commit()\n",
    "print(\"Dimensions populated.\")\n",
    "# Insert transaction headers\n",
    "cur.executescript(\"\"\"\n",
    "INSERT OR IGNORE INTO transactions (\n",
    "  txn_code, customer_id, payment_method_id, channel_id, txn_ts, discount_applied, year, month, day, dow\n",
    ")\n",
    "SELECT\n",
    "  h.transaction_id,\n",
    "  (SELECT customer_id FROM customers WHERE customer_code = h.customer_id),\n",
    "  (SELECT payment_method_id FROM payment_methods WHERE method_name = h.payment_method),\n",
    "  (SELECT channel_id FROM channels WHERE channel_name = h.location),\n",
    "  h.transaction_date,\n",
    "  h.discount_applied,\n",
    "  h.year, h.month, h.day,\n",
    "  CAST(strftime('%w', h.transaction_date) AS INTEGER)\n",
    "FROM stg_txn_header h\n",
    "WHERE h.transaction_id IS NOT NULL;\n",
    "\"\"\")\n",
    "\n",
    "con.commit()\n",
    "print(\"Transaction headers inserted.\")\n",
    "# Insert transaction Items\n",
    "# Build a view-like temp table with cents conversions via pandas for speed & clarity\n",
    "ti = stg[['transaction_id','item','price_per_unit','quantity','discount_amount','discount_percentage','total_spent']].copy()\n",
    "\n",
    "# Filter valid lines: need transaction_id and item, quantity > 0, price >= 0\n",
    "ti = ti[ti['transaction_id'].notna() & ti['item'].notna()].copy()\n",
    "ti['quantity'] = pd.to_numeric(ti['quantity'], errors='coerce')\n",
    "ti['price_per_unit'] = pd.to_numeric(ti['price_per_unit'], errors='coerce')\n",
    "ti['discount_amount'] = pd.to_numeric(ti['discount_amount'], errors='coerce').fillna(0.0)\n",
    "ti['discount_percentage'] = pd.to_numeric(ti['discount_percentage'], errors='coerce').fillna(0.0)\n",
    "ti['total_spent'] = pd.to_numeric(ti['total_spent'], errors='coerce').fillna(0.0)\n",
    "\n",
    "ti = ti[(ti['quantity'] > 0) & (ti['price_per_unit'] >= 0)]\n",
    "\n",
    "# Convert to cents\n",
    "ti['price_per_unit_c'] = ti['price_per_unit'].apply(to_cents)\n",
    "ti['discount_amount_c'] = ti['discount_amount'].apply(to_cents)\n",
    "ti['line_total_c']      = ti['total_spent'].apply(to_cents)\n",
    "\n",
    "# Write a temp table for bulk insert via SQL join\n",
    "ti.to_sql('stg_ti', con, if_exists='replace', index=False)\n",
    "\n",
    "# Insert with FK mapping + let the trigger validate math\n",
    "cur = con.cursor()\n",
    "cur.executescript(\"\"\"\n",
    "INSERT INTO transaction_items (\n",
    "  txn_id, item_id, price_per_unit_c, quantity, discount_amount_c, discount_pct, line_total_c\n",
    ")\n",
    "SELECT\n",
    "  t.txn_id,\n",
    "  i.item_id,\n",
    "  st.price_per_unit_c,\n",
    "  st.quantity,\n",
    "  st.discount_amount_c,\n",
    "  COALESCE(st.discount_percentage, 0.0),\n",
    "  st.line_total_c\n",
    "FROM stg_ti st\n",
    "JOIN transactions t ON t.txn_code = st.transaction_id\n",
    "JOIN items i        ON i.item_code = st.item;\n",
    "\"\"\")\n",
    "con.commit()\n",
    "\n",
    "# Clean up the temp table\n",
    "cur.execute(\"DROP TABLE IF EXISTS stg_ti;\")\n",
    "con.commit()\n",
    "print(\"Transaction items inserted.\")\n",
    "print(\"Validation and Display below.\")\n",
    "q = {}\n",
    "\n",
    "q['counts'] = \"\"\"\n",
    "SELECT \n",
    " (SELECT COUNT(*) FROM customers)        AS customers,\n",
    " (SELECT COUNT(*) FROM categories)       AS categories,\n",
    " (SELECT COUNT(*) FROM items)            AS items,\n",
    " (SELECT COUNT(*) FROM payment_methods)  AS payment_methods,\n",
    " (SELECT COUNT(*) FROM channels)         AS channels,\n",
    " (SELECT COUNT(*) FROM transactions)     AS transactions,\n",
    " (SELECT COUNT(*) FROM transaction_items) AS transaction_items;\n",
    "\"\"\"\n",
    "\n",
    "q['sample_txn'] = \"\"\"\n",
    "SELECT * FROM v_transactions\n",
    "ORDER BY txn_ts DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "q['top_items'] = \"\"\"\n",
    "SELECT category_name, item_code, SUM(line_total) AS revenue\n",
    "FROM v_transaction_items\n",
    "GROUP BY category_name, item_code\n",
    "ORDER BY revenue DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "for name, sql in q.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    try:\n",
    "        display(pd.read_sql(sql, con))\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
